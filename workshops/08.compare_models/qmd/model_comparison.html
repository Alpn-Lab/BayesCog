<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.7">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Model comparison – BayesCog - Bayesian Statistics and Hierarchical Bayesian Modeling for Psychological Science</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../workshops/09.debugging/qmd/intro.html" rel="next">
<link href="../../../workshops/08.compare_models/qmd/intro.html" rel="prev">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-fe43d0015be6fd5bd60fe62033074fe8.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap-001260dd2da97ba1fc6ab87e8be34c98.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../../styles.css">
</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../../workshops/08.compare_models/qmd/intro.html">Workshop 8: Model comparison</a></li><li class="breadcrumb-item"><a href="../../../workshops/08.compare_models/qmd/model_comparison.html">Model comparison</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-center sidebar-header">
      <a href="../../../index.html" class="sidebar-logo-link">
      <img src="../../../images/alpn_logo_with_text.png" alt="" class="sidebar-logo py-0 d-lg-inline d-none">
      </a>
      <div class="sidebar-tools-main tools-wide">
    <a href="https://alpnlab.github.io" title="ALPN Lab Website" class="quarto-navigation-tool px-1" aria-label="ALPN Lab Website"><i class="bi bi-globe"></i></a>
    <a href="https://github.com/alpnlab" title="ALPN Lab GitHub" class="quarto-navigation-tool px-1" aria-label="ALPN Lab GitHub"><i class="bi bi-github"></i></a>
    <a href="https://twitter.com/ALPN_Lab" title="ALPN Lab Twitter" class="quarto-navigation-tool px-1" aria-label="ALPN Lab Twitter"><i class="bi bi-twitter"></i></a>
</div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Welcome to BayesCog!</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../course_overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Course overview</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false">
 <span class="menu-text">Workshop 1: R Basics</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../workshops/01.R_basics/qmd/intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Workshop 1: Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../workshops/01.R_basics/qmd/introduction_to_r.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction to R/RStudio</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../workshops/01.R_basics/qmd/working_with_data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Working with data in R</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false">
 <span class="menu-text">Workshop 2: Probability and an introduction to Bayes’ theorem</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../workshops/01.R_basics/qmd/intro_probability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Workshop 2: Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../workshops/01.R_basics/qmd/probability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Probability and Bayes’ theorem</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false">
 <span class="menu-text">Workshop 3: Building simple models conceptually</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../workshops/02.binomial_globe/qmd/intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Workshop 3: Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../workshops/02.binomial_globe/qmd/data_and_parameters.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Linking data to parameters</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../workshops/02.binomial_globe/qmd/binomial_model.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">The globe-tossing experiment</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../workshops/02.binomial_globe/qmd/mcmc.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Markov chain Monte Carlo</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false">
 <span class="menu-text">Workshop 4: Introduction to building models in Stan</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../workshops/02.binomial_globe/qmd/stan_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Workshop 4: Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../workshops/02.binomial_globe/qmd/stan_binomial.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Building models in Stan</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false">
 <span class="menu-text">Workshop 5: Bernoulli and linear regression models</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../workshops/03.bernoulli_coin/qmd/intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Workshop 5: Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../workshops/03.bernoulli_coin/qmd/stan_notes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Technical notes on Stan</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../workshops/03.bernoulli_coin/qmd/bernoulli_and_regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Bernoulli and linear regression models</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="false">
 <span class="menu-text">Workshop 6: Reinforcement learning models</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../workshops/06.reinforcement_learning/qmd/intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Workshop 6: Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../workshops/06.reinforcement_learning/qmd/rl_concepts.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Fundamentals of cognitive modeling and reinforcement learning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../workshops/06.reinforcement_learning/qmd/rl_stan.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Implementing the Rescorla-Wagner model in Stan</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="false">
 <span class="menu-text">Workshop 7: Hierachical Bayesian modeling</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../workshops/06.reinforcement_learning/qmd/hrch_rl_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Workshop 7: Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../workshops/06.reinforcement_learning/qmd/hierarchical_modeling.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Hierarchical Bayesian models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../workshops/07.optm_rl/qmd/optim.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Reparameterization and optimizing Stan code</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true">
 <span class="menu-text">Workshop 8: Model comparison</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../workshops/08.compare_models/qmd/intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Workshop 8: Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../workshops/08.compare_models/qmd/model_comparison.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Model comparison</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="false">
 <span class="menu-text">Workshop 9: Debugging in Stan</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../workshops/09.debugging/qmd/intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Workshop 9: Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../workshops/09.debugging/qmd/debugging.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Debugging in Stan</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../workshops/09.debugging/qmd/workflow.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">A principled modeling workflow</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="false">
 <span class="menu-text">Bonus workshop: Introduction to model-based fMRI</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-10" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-10" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../workshops/10.model_based/qmd/model_fmri.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction to model-based fMRI</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../conclusion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Acknowledgements</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../resources.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Resources</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#model-fitting-and-the-goldilocks-principle" id="toc-model-fitting-and-the-goldilocks-principle" class="nav-link active" data-scroll-target="#model-fitting-and-the-goldilocks-principle">Model fitting and the Goldilocks principle</a></li>
  <li><a href="#information-criteria" id="toc-information-criteria" class="nav-link" data-scroll-target="#information-criteria">Information criteria</a></li>
  <li><a href="#model-comparison-using-waic" id="toc-model-comparison-using-waic" class="nav-link" data-scroll-target="#model-comparison-using-waic">Model comparison using WAIC</a>
  <ul class="collapse">
  <li><a href="#introducing-the-fictitious-rl-model" id="toc-introducing-the-fictitious-rl-model" class="nav-link" data-scroll-target="#introducing-the-fictitious-rl-model">Introducing the Fictitious RL model</a></li>
  </ul></li>
  <li><a href="#posterior-predictive-checks" id="toc-posterior-predictive-checks" class="nav-link" data-scroll-target="#posterior-predictive-checks">Posterior predictive checks</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/sohaamir/BayesCog/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../../workshops/08.compare_models/qmd/intro.html">Workshop 8: Model comparison</a></li><li class="breadcrumb-item"><a href="../../../workshops/08.compare_models/qmd/model_comparison.html">Model comparison</a></li></ol></nav>
<div class="quarto-title">
<h1 class="title">Model comparison</h1>
<p class="subtitle lead">Model fitting, information criteria and posterior predictive checks</p>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>Let’s think back to the quote by George Box mentioned earlier in the course:</p>
<div class="quote-large" style="font-size: 1.3em">
<blockquote class="blockquote">
<p>“Essentially, all the models are wrong, but some are useful.” - George E.P. Box (1976)</p>
</blockquote>
</div>
<p>This is particularly relevant in cognitive modeling, <strong>where no model can perfectly capture human cognition.</strong> However, some models provide more useful approximations than others.</p>
<p>Consider our reinforcement learning example: we might have several competing hypotheses about how people learn from rewards. Perhaps some participants use a simple learning strategy with a single learning rate, while others might use different learning rates for positive and negative outcomes. Or maybe some individuals incorporate uncertainty into their learning process. Each of these hypotheses can be formalized as a different computational model, but which one best describes our participants’ behaviour?</p>
<p>Model comparison provides us with systematic tools to answer this question. Rather than simply accepting the first model that seems to fit our data reasonably well, we can fit multiple models and compare which is best. In relation to Box’s quote, we want to see which model is the least wrong!</p>
<section id="model-fitting-and-the-goldilocks-principle" class="level2">
<h2 class="anchored" data-anchor-id="model-fitting-and-the-goldilocks-principle">Model fitting and the Goldilocks principle</h2>
<p>Have a look at the graph below, which shows polynomials of different orders being fitted to some data, where <span class="math inline">\(M\)</span> represents the order of the polynomial:</p>
<div style="height: 10px;">

</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../../../images/08.compare_models/polynomial_overfitting.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:60.0%"></p>
</figure>
</div>
<p>Looking at the model fits, which order-polynomial is ‘best’?</p>
<p>At first glance, you might think the <span class="math inline">\(M = 7\)</span> model is ‘best’ since it passes exactly through each data point. However, this intuition leads us to the concept of overfitting - where a model learns to fit the noise in the specific data provided rather than explaining the underlying pattern more generally.</p>
<p>Overfitting can be humorously described by a John von Neumann quote recalled by Enrico Fermi:</p>
<div class="quote-large" style="font-size: 1.4em">
<blockquote class="blockquote">
<p>“With four parameters I can fit an elephant, and with five I can make him wiggle his trunk.”</p>
</blockquote>
</div>
<p>Elephants aside, his point was that <strong>with enough parameters, you can fit any pattern in your data</strong> - even if that pattern is just random noise.</p>
<p>This brings us to model-fitting, a fundamental concept in model selection illustrated in the figure below<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>:</p>
<div style="height: 20px;">

</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../../../images/08.compare_models/overfitting.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%"></p>
</figure>
</div>
<div class="image-caption" style="font-size: 1.4em;">
<p>Model fitting is an example of the Goldilocks principle: it needs to be just right</p>
</div>
<p>The graph shows that as we increase model complexity, we initially see improvements in how well our model fits the data. However, there comes a point where adding more complexity leads to overfitting.</p>
<p>The figure shows two crucial curves:</p>
<ul>
<li>The <strong>“Goodness of fit”</strong> curve shows how well the model fits the observed data, which continues to improve with complexity.</li>
<li>The <strong>“Generalizability”</strong> curve shows how well the model performs on new, unseen data. This curve peaks and then declines as the model becomes too complex.</li>
</ul>
<p>Looking back at our polynomial example, while <span class="math inline">\(M = 7\)</span> undoubedtly gives us the best fit to our observed data points, it would likely perform poorly if we tried to use it to predict new data. <strong>The model has accurately but specifically learned the noise in our sample rather than the more general relationship we’re trying to understand.</strong></p>
<p>Ultimately, we need to find a sweet spot - a balance between underfitting and overfitting.</p>
<p>But how do we determine which model is best? A more philosophical rule follows Ockham’s razor, which (in one variation) states that:</p>
<div class="quote-large" style="font-size: 1.3em">
<blockquote class="blockquote">
<p>“When having two competing theories that make exactly the same predictions, the simpler one is the better.” - original maxim attributed to William of Ockham (c.&nbsp;1285 - 1347)</p>
</blockquote>
</div>
<p>Specifically concerning model selection, we should therefore prefer simpler models when they provide similar explanatory power or make fewer assumptions; <span class="math inline">\(M = 2\)</span> or <span class="math inline">\(M = 4\)</span> might provide the best balance - capturing the main trend in the data without overfitting.</p>
</section>
<section id="information-criteria" class="level2">
<h2 class="anchored" data-anchor-id="information-criteria">Information criteria</h2>
<p>As a result, we would like to know which model best fits the data but also generalizes to new unobserved data.</p>
<p>But how do we define and implement this objectively? One way is through cross-validation.</p>
<div style="height: 20px;">

</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../../../images/08.compare_models/cross_validation.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:80.0%"></p>
</figure>
</div>
<div class="image-caption" style="font-size: 1.2em;">
<p>Cross-validation (<span class="math inline">\(k\)</span>-fold) involves fitting a model to most of the data and testing it on the remainder <span class="math inline">\(k\)</span> times</p>
</div>
<p>The basic principle is straightforward: we divide our dataset into two parts:</p>
<p><strong>1. A training set</strong> that we use to fit our model</p>
<p><strong>2. A validation set</strong> that we use to test how well our model predicts new, unseen data</p>
<p>The figure above shows a specific type: <span class="math inline">\(k\)</span>-fold cross-validation, where the data is divided into <span class="math inline">\(k\)</span> equal sections, and each section takes a turn being the validation set while the remaining sections form the training set.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Leave-One-Out Cross Validation (LOOCV)">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Leave-One-Out Cross Validation (LOOCV)
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Leave-One-Out Cross Validation (LOOCV) is a special case of <span class="math inline">\(k\)</span>-fold cross-validation</strong> where <span class="math inline">\(k\)</span> equals the number of data points in the dataset, meaning you leave out just one data point for validation while training on all others, repeating for every point in the dataset. While LOOCV provides nearly unbiased estimates of model performance, it can be computationally expensive for large datasets since you need to train the model <span class="math inline">\(n\)</span> times (where <span class="math inline">\(n\)</span> is your sample size), compared to <span class="math inline">\(k\)</span>-fold which only requires training <span class="math inline">\(k\)</span> times.</p>
</div>
</div>
<p>Cross-validation is particularly useful when we have a fixed amount of data and won’t be collecting more. Rather than using all our data to fit the model, we deliberately hold some back to simulate how well our model might perform on future observations. <strong>This helps us detect overfitting - if a model performs much better on the training data than the validation data, it’s likely overfitting.</strong></p>
<p>However, cross-validation comes with some practical limitations. We need to perform this process for each model we want to compare, which can be computationally intensive. For complex models or large datasets, this can make cross-validation quite time-consuming.</p>
<p>In the Bayesian context, there’s an interesting alternative approach. While nothing prevents us from using cross-validation with Bayesian models, holding out data makes our posterior distributions more diffuse, since we’re using less information to estimate our parameters. Instead, Bayesians typically condition on all available data and use “information criteria” to evaluate how well a model is expected to predict out of sample. <strong>While cross-validation directly tests this by holding out data, information criteria provide mathematical approximations to cross-validation that are computationally more efficient.</strong></p>
<p>Information criteria are mathematical formulas that balance two components:</p>
<ol type="1">
<li><p>How well the model fits the observed data (goodness of fit)</p></li>
<li><p>A penalty term for model complexity (to prevent overfitting)</p></li>
</ol>
<p>Commonly used information criteria are:</p>
<div style="font-size: 22px;">
<strong>Akaike Information Criterion (AIC)</strong>
</div>
<div style="height: 16px;">

</div>
<p>The original information criterion, introduced by Hirotugu Akaike, is calculated as:</p>
<p><span class="math display">\[AIC = -2(\log\mathcal{L}) + 2k\]</span></p>
<p>where:</p>
<p><span class="math inline">\(\mathcal{L}\)</span> is the maximum likelihood , and <span class="math inline">\(k\)</span> is the number of parameters in the model.</p>
<div style="font-size: 22px;">
<strong>Deviance Information Criterion (DIC)</strong>
</div>
<div style="height: 16px;">

</div>
<p>DIC was developed specifically for Bayesian models, extending AIC to handle hierarchical models:</p>
<p><span class="math display">\[DIC = -2(\log\mathcal{L}) + 2p_D\]</span></p>
<p>where:</p>
<p><span class="math inline">\(p_D\)</span> is the effective number of parameters, accounting for how parameters might be constrained by the hierarchical structure.</p>
<div style="font-size: 22px;">
<strong>Widely Applicable Information Criterion (WAIC)</strong>
</div>
<div style="height: 16px;">

</div>
<p><strong>WAIC is currently considered the most accurate approximation to leave-one-out (LOO) cross-validation.</strong> It computes the predictive accuracy for each data point and includes a correction for effective number of parameters:</p>
<p><span class="math display">\[WAIC = -2(lpd - p_{WAIC})\]</span></p>
<p>where:</p>
<p><span class="math inline">\(lpd\)</span> is the log pointwise predictive density, and <span class="math inline">\(p_{WAIC}\)</span> accounts for model complexity, determined by:</p>
<p><span class="math display">\[lpd = \sum_{i=1}^n \log \left(\frac{1}{S}\sum_{s=1}^S p(y_i|\theta^s)\right)\]</span></p>
<p><span class="math display">\[p_{WAIC} = \sum_{i=1}^n V_{s=1}^S(\log p(y_i|\theta^s))\]</span></p>
<p>where:</p>
<ul>
<li><p><span class="math inline">\(S\)</span> is the number of posterior samples,</p></li>
<li><p><span class="math inline">\(\theta^s\)</span> are the parameter values in sample <span class="math inline">\(s\)</span>,</p></li>
<li><p>and <span class="math inline">\(V\)</span> represents the sample variance over the <span class="math inline">\(S\)</span> samples.</p></li>
</ul>
<p><strong>We will be using the WAIC for model comparison in this course, as it provides the best approximation to leave-one-out cross-validation.</strong> Unlike AIC and DIC, WAIC uses the full posterior distribution rather than just point estimates, making it more appropriate for Bayesian models.</p>
<p>We can see this in the table below, which compares the accuracy of different information criteria to the leave-one-out cross-validation (LOO-CV) ground truth<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>. As highlighted, the WAIC performs best relative to the AIC and DIC.</p>
<div style="height: 20px;">

</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../../../images/08.compare_models/ic_comparison.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:70.0%"></p>
</figure>
</div>
<div class="image-caption" style="font-size: 1.5em;">
<p>WAIC outperforms AIC and DIC when approximating LOOCV</p>
</div>
<p>How is the WAIC calculated? Remember that the likelihood tells us how probable our observed data is under a particular model, with higher likelihood values suggesting the model does a better job of explaining the observed data. <strong>However, simply choosing the model with the highest likelihood can be misleading as this would always favour more complex models.</strong></p>
<p>WAIC estimates how well our model would predict new data (out-of-sample prediction) by:</p>
<ul>
<li><p>Using the likelihood to measure how well the model fits each individual data point</p></li>
<li><p>Accounting for uncertainty in our parameter estimates by averaging across many possible parameter values (our posterior samples)</p></li>
<li><p>Penalizing models that make very different predictions when parameters change slightly (a sign of overfitting)</p></li>
</ul>
<p><strong>The resulting WAIC score is on the deviance scale - lower values indicate better predictive models.</strong> For example, if Model A has a WAIC of 500 and Model B has a WAIC of 600, Model A is predicted to do better at generalizing to new data. When comparing models however, we typically look at WAIC differences.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Bayesian Information Criterion">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Bayesian Information Criterion
</div>
</div>
<div class="callout-body-container callout-body">
<p>Note that while another type, Bayesian Information Criterion (BIC) is also commonly used, it has a different goal: finding the “true” model under specific assumptions about the data-generating process. Since in cognitive modeling we typically assume all models are approximations, WAIC’s focus on predictive accuracy is more appropriate for our purpose.</p>
</div>
</div>
</section>
<section id="model-comparison-using-waic" class="level2">
<h2 class="anchored" data-anchor-id="model-comparison-using-waic">Model comparison using WAIC</h2>
<p>Let’s now apply the WAIC practically in Stan to compare model performance across multiple reinforcement learning models.</p>
<p>We have already utilized several blocks beyond the basic <code>data</code>, <code>parameters</code>, and <code>model</code> blocks in Stan:</p>
<ul>
<li><p><code>transformed data</code> for pre-processing data before sampling begins.</p></li>
<li><p><code>transformed parameters</code> for implementing parameter transformations, including reparameterization.</p></li>
</ul>
<p><strong>When calculating the log-likelihood, we use another optional block - <code>generated quantities</code> for post-processing our posterior samples after the main sampling is complete.</strong> It’s ideal for computing quantities we need for model comparison (like log-likelihoods) or predictions.</p>
<p>So, building from our existing reparameterized hierarchical RL model from the last workshop, we simply add a <code>generated quantities</code> block, where we calculate log-likelihoods for each subject:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="kw">generated quantities</span> {</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>,<span class="kw">upper</span>=<span class="dv">1</span>&gt; lr_mu; </span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span>&lt;<span class="kw">lower</span>=<span class="dv">0</span>,<span class="kw">upper</span>=<span class="dv">3</span>&gt; tau_mu;</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>  <span class="dt">real</span> log_lik[nSubjects];</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>  lr_mu  = Phi_approx(lr_mu_raw);</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>  tau_mu = Phi_approx(tau_mu_raw) * <span class="dv">3</span>;</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>  { <span class="co">// local section, this saves time and space</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (s <span class="cf">in</span> <span class="dv">1</span>:nSubjects) {</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>      <span class="dt">vector</span>[<span class="dv">2</span>] v; </span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>      <span class="dt">real</span> pe;    </span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>      log_lik[s] = <span class="dv">0</span>;</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>      v = initV;</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>      <span class="cf">for</span> (t <span class="cf">in</span> <span class="dv">1</span>:nTrials) {    </span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>        log_lik[s] = log_lik[s] + categorical_logit_lpmf(choice[s,t] | tau[s] * v);    </span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>              </span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>        pe = reward[s,t] - v[choice[s,t]];      </span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>        v[choice[s,t]] = v[choice[s,t]] + lr[s] * pe; </span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>      }</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>    }    </span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>In this block, we declare log-likelihoods for each subject:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="dt">real</span> log_lik[nSubjects];  <span class="co">// Declare log-likelihood array</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>initialize their log-likelihood to zero:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>log_lik[s] = <span class="dv">0</span>;</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>and loop through trials, accumulating log-likelihood:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>log_lik[s] = log_lik[s] + categorical_logit_lpmf(choice[s,t] | tau[s] * v);</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>This line above is important and calculates how likely (the log-probability) it was that the participant made the choice they actually made, according to our model.</strong></p>
<p>Let’s break this line down further:</p>
<p>Recall that our data (<code>choice[s,t]</code>) is discrete - participants choose either option 1 or 2. We therefore can’t use continuous distributions like normal for discrete data. Instead, we use the categorical distribution, which gives probabilities for discrete outcomes.</p>
<ul>
<li><p>Specifically we use the <code>categorical_logit_lpmf</code> (categorical log probability mass function) because we’re working with discrete data and log-odds.</p></li>
<li><p>The vertical bar <code>|</code> in <code>choice[s,t] | tau[s] * v</code> represents Bayesian conditioning. It reads as “the probability of observing <code>choice[s,t]</code> given <code>tau[s] * v</code>”. This directly reflects the Bayesian relationship between our data, parameters and our model’s predictions.</p></li>
</ul>
<p>So to summarise:</p>
<ol type="1">
<li><p>Our model predicts values for each option (stored in <code>v</code>)</p></li>
<li><p>Based on these values and the participant’s inverse temperature (<code>tau[s]</code>), we can calculate how likely they were to choose each option</p></li>
<li><p>We then look at what they actually chose (<code>choice[s,t]</code>)</p></li>
<li><p>The function calculates the log probability that they would make that specific choice</p></li>
<li><p>We then add this log probability to a running total (<code>log_lik[s]</code>) for that participant. By doing this for every trial, we get a measure of how well our model predicted that participant’s entire sequence of choices.</p></li>
</ol>
<p>Once we have the log likelihoods, we can then calculate model comparison metrics using the <code>loo</code> package in <code>R</code><a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>:</p>
<p>This is rather simple and firstly involves extracting the log-likelihood matrix from our Stan fit object:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>LL1 <span class="ot">&lt;-</span> <span class="fu">extract_log_lik</span>(stanfit)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Then we can simple compute either the WAIC or LOO-CV (Leave-One-Out Cross-Validation) by Pareto Smoothed Importance Sampling (PSIS):</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>waic1 <span class="ot">&lt;-</span> <span class="fu">waic</span>(LL1)  <span class="co"># WAIC calculation</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>loo1 <span class="ot">&lt;-</span> <span class="fu">loo</span>(LL1)    <span class="co"># PSIS-LOO calculation</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="callout callout-style-default callout-tip callout-titled" title="WAIC or PSIS-LOO?">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
WAIC or PSIS-LOO?
</div>
</div>
<div class="callout-body-container callout-body">
<p>WAIC and PSIS-LOO are both methods for estimating out-of-sample prediction accuracy, but they approach it differently. WAIC approximates leave-one-out cross-validation using the entire dataset, while PSIS-LOO uses importance sampling to approximate true leave-one-out cross-validation. In practice, they often give very similar results, and both are valid choices for model comparison.</p>
</div>
</div>
<p>The (hypothetical) output below shows us several key metrics computed from the <code>loo</code> package, in the case below as a 4000 x 20 log-likelihood matrix (representing 4000 posterior samples for 20 subjects):</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>Computed from <span class="dv">4000</span> by <span class="dv">20</span> log<span class="sc">-</span>likelihood matrix</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>         Estimate  SE</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>elpd_loo    <span class="sc">-</span><span class="fl">29.5</span> <span class="fl">3.3</span> </span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>p_loo         <span class="fl">2.7</span> <span class="fl">1.0</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>looic        <span class="fl">58.9</span> <span class="fl">6.7</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Where:</p>
<ul>
<li><code>elpd</code>: expected log predictive density (how well a model is expected to predict new, unseen data)</li>
<li><code>p_loo/p_waic</code>: effective number of parameters</li>
<li><code>looic/waic</code>: information criterion value</li>
</ul>
<p>What we are most interested in is the <code>looic</code> estimate, which in this case is 58.9. Remember that lower values mean a better model!</p>
<section id="introducing-the-fictitious-rl-model" class="level3">
<h3 class="anchored" data-anchor-id="introducing-the-fictitious-rl-model">Introducing the Fictitious RL model</h3>
<p>Now that we know what to expect, let’s run our model comparison. However for this exercise, we will use a different dataset to what we have used prior.</p>
<p>So far, we’ve worked with reinforcement learning tasks where reward probabilities remained constant. However, in real life, reward contingencies often change - what was once rewarding might become unfavorable, and vice versa. The reversal learning task<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> captures this dynamic nature of learning.</p>
<div style="height: 20px;">

</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../../../images/08.compare_models/reversals.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:95.0%"></p>
</figure>
</div>
<div class="image-caption" style="font-size: 1.4em;">
<p>An example reversal learning reward contingency, with reversals every 8-12 trials</p>
</div>
<p>In a conventional reversal learning task, participants choose between two stimuli, where initially, one stimulus might have a higher reward probability (say 70%) while the other has a lower probability (30%). However, after a certain number of trials, these probabilities switch or “reverse” - the previously better option becomes the worse option and vice versa. This creates a more challenging learning environment where participants must detect and adapt to these changes. The block length, or the number of trials between each reversal, is also variable; in the example above it is constrained to occur between every 8-12 trials.</p>
<p>Of course, to perform model comparison, we need more than one model! We already have our standard Rescorla-Wagner (RW) model that we’ve used before, so now we will compare it with a variant - the Fictitious (or Counterfactual) RL model.</p>
<p>Recall that the standard RW model updates only the value of the chosen option based on the received reward:</p>
<p><span class="math display">\[V_{t+1}^c = V_t^c + \alpha \cdot PE\]</span></p>
<p>with the prediction error <span class="math inline">\(PE\)</span> defined as:</p>
<p><span class="math display">\[PE = R_t - V_t^c\]</span></p>
<p>where:</p>
<ul>
<li><p><span class="math inline">\(V_t^c\)</span> is the value of the chosen option,</p></li>
<li><p><span class="math inline">\(\alpha\)</span> is the learning rate.</p></li>
</ul>
<p><strong>The Fictitious RL model extends the basic Rescorla-Wagner by also updating the value of the unchosen option.</strong> The key insight is that in binary choice tasks with complementary rewards (like our reversal learning task), not receiving a reward on one option provides information about what might have happened had we chosen the other option.</p>
<p>The model captures this through these equations:</p>
<p><span class="math display">\[V_{t+1}^c = V_t^c + \alpha \cdot PE\]</span> and simultaneously:</p>
<p><span class="math display">\[V_{t+1}^{nc} = V_t^{nc} + \alpha \cdot PE_{nc}\]</span></p>
<p>where:</p>
<p><span class="math display">\[PE = R_t - V_t^c\]</span> and:</p>
<p><span class="math display">\[PE_{nc} = -R_t - V_t^{nc}\]</span></p>
<p>The crucial difference are in the second and fourth equations: the model updates the value of the non-chosen option (<span class="math inline">\(V_t^{nc}\)</span>) using a counterfactual prediction error (<span class="math inline">\(PE_{nc}\)</span>).</p>
<p>The negative sign before <span class="math inline">\(R_t\)</span> in <span class="math inline">\(PE_{nc}\)</span> in the last equation reflects the complementary nature of the rewards - if one option gives a reward, the other option would have given no reward, and vice versa. <strong>This counterfactual learning might be particularly useful in reversal learning tasks, as it allows participants to learn about both options on every trial, potentially enabling faster adaptation to reversals.</strong></p>
<p>To better understand the difference between the two models, the graphs below plot the value update calculated by both models with the learning rate (<span class="math inline">\(η = 0.35\)</span>) and inverse temperature (<span class="math inline">\(τ = 1.2\)</span>) parameters fixed to be the same for both:</p>
<div style="height: 20px;">

</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../../../images/08.compare_models/rl_time_series.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:90.0%"></p>
</figure>
</div>
<div class="image-caption" style="font-size: 1.3em;">
<p>Value and choice predicted by the Fictitious and Rescorla-Wagner (Simple) RL models with fixed learning rates and inverse temperatures</p>
</div>
<p>The crucial difference between the models is visible in how the unchosen option’s value changes. <strong>In the Simple RL model, the unchosen option’s value remains flat/unchanged until it is chosen again.</strong> This creates “plateaus” in the value lines when an option isn’t chosen, for example in the orange line around trials 20-30, where it remains completely flat while option A is being chosen.</p>
<p><strong>Conversely, for the Fictitious RL model, where both options’ values are updated on every trial, no flat plateaus are visible.</strong> Subsequently, the value difference between the options for both models, highlights how this is - on average, across all trials - larger for the Fictitious RL model compared to the Simple RL model. As a result, because larger value differences could translate into an easier choice between the two options, the Fictitious RL represents a potential cognitive process that people use.</p>
<p>Now that we have two models, we can compare them directly using the WAIC, and test whether participants actually use this additional information when making decisions in the reversal learning task.</p>
<p>The Stan implementation of the Fictitious RL can be found in <code>_scripts/comparing_models_model2.stan</code>. Comparing this to the Simple RL <code>comparing_models_model1.stan</code>, we can’t see much of a difference. In fact, the only major difference is in the <code>model</code> block.</p>
<p>In the Simple RL, we have a simple update rule that only modifies the value of the chosen option:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>pe = reward[s,t] - v[choice[s,t]];      </span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>v[choice[s,t]] = v[choice[s,t]] + lr[s] * pe;</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This shows that on each trial, the model:</p>
<ul>
<li><p>Calculates a prediction error (<code>pe</code>) for the chosen option</p></li>
<li><p>Updates only the value of the chosen option using this prediction error</p></li>
</ul>
<p>The second model extends this by also updating the unchosen option’s value:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>pe = reward[s,t] - v[choice[s,t]];   </span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>penc = -reward[s,t] - v[<span class="dv">3</span> - choice[s,t]];</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>v[choice[s,t]] = v[choice[s,t]] + lr[s] * pe; </span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>v[<span class="dv">3</span> - choice[s,t]] = v[<span class="dv">3</span> - choice[s,t]] + lr[s] * penc;</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>After declaring a new variable <code>penc</code> for the counterfactual prediction error <code>real penc;</code>:</p>
<ul>
<li><p>We use <code>3 - choice[s,t]</code> to index the unchosen option (since if choice is 1, we want 2, and if choice is 2, we want 1)</p></li>
<li><p>We calculate <code>penc</code> using the negative of the reward (<code>-reward[s,t]</code>)</p></li>
<li><p>We update both the chosen and unchosen options’ values on each trial</p></li>
</ul>
<div class="callout callout-style-default callout-note callout-titled" title="Exercise 13">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Exercise 13
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>1. Run both models using the <code>R</code> script <code>compare_models_main.R</code>, and examine the LOOIC values for each. Which is best?</strong></p>
<div class="callout callout-style-default callout-tip callout-titled" title="Click to reveal the solution">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Click to reveal the solution
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The results should look (roughly<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>) like this:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> LL1 <span class="ot">&lt;-</span> <span class="fu">extract_log_lik</span>(fit_rl1)</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> ( loo1 <span class="ot">&lt;-</span> <span class="fu">loo</span>(LL1) )</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>Computed from <span class="dv">4000</span> by <span class="dv">10</span> log<span class="sc">-</span>likelihood matrix</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>         Estimate   SE</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>elpd_loo   <span class="sc">-</span><span class="fl">389.4</span> <span class="fl">15.4</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>p_loo         <span class="fl">3.5</span>  <span class="fl">0.7</span></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>looic       <span class="fl">778.7</span> <span class="fl">30.8</span></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> ( loo2 <span class="ot">&lt;-</span> <span class="fu">loo</span>(LL2) )</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>Computed from <span class="dv">4000</span> by <span class="dv">10</span> log<span class="sc">-</span>likelihood matrix</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>         Estimate   SE</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>elpd_loo   <span class="sc">-</span><span class="fl">281.6</span> <span class="fl">17.5</span></span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>p_loo         <span class="fl">3.8</span>  <span class="fl">0.5</span></span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>looic       <span class="fl">563.2</span> <span class="fl">35.1</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The lower LOOIC value for the second model (Fictitious RL) (~563 vs ~779) suggests it provides a better fit to the data than the Rescorla-Wagner model.</p>
</div>
</div>
</div>
</div>
</div>
</section>
</section>
<section id="posterior-predictive-checks" class="level2">
<h2 class="anchored" data-anchor-id="posterior-predictive-checks">Posterior predictive checks</h2>
<p>We have just compared our two RL models objectively using information criteria, suggesting that the Fictitious RL model will better predict new, unseen data from our reversal learning task and more accurately captures the underlying latent cognitive processes that generated the observed data. But while measurements like WAIC and LOO help us compare models quantitatively, posterior predictive checks allow us to visually assess how well our models actually capture patterns in the observed data.</p>
<p><strong>The basic idea of posterior predictive checks is simple: we ask our model to generate simulated data. If our model is good, data simulated from it should look similar to our actual data.</strong> Not only does running posterior predictive checks allow us to validate good fitting models, it also can be used to falsify bad fitting ones.</p>
<p>To perform posterior predictive checks, we need to add a section to our Stan models that generates simulated data. We do this in the <code>generated quantities</code> block.</p>
<p><strong>Importantly, because we are using a Bayesian approach, we don’t just simulate from the mean parameter estimates - instead, we simulate new data using every posterior sample of our parameters.</strong> This is crucial because it allows us to incorporate our uncertainty about the parameters into our predictions.</p>
<p>From our Stan model, we get posterior samples for all parameters - in our case, 4000 draws from the posterior distribution of each parameter (learning rates, inverse temperatures, etc.). For each of these 4000 parameter sets, we then simulate an entire experiment worth of data using those specific parameters. This is what’s happening in the corresponding <code>generated quantities</code> block:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode stan code-with-copy"><code class="sourceCode stan"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="kw">generated quantities</span> {</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">// ... existing code for log likelihood ...</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>  <span class="co">// Generate predicted choices</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>  <span class="dt">array</span>[nSubjects, nTrials] <span class="dt">int</span> y_pred;</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>  { <span class="co">// local section</span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (s <span class="cf">in</span> <span class="dv">1</span>:nSubjects) {</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>      <span class="dt">vector</span>[<span class="dv">2</span>] v;</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>      <span class="dt">real</span> pe;</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>      v = initV;</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>      <span class="cf">for</span> (t <span class="cf">in</span> <span class="dv">1</span>:nTrials) {</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>        <span class="co">// Generate predicted choice from current values</span></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>        y_pred[s,t] = categorical_logit_rng(tau[s] * v);</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>        <span class="co">// Update values using actual reward</span></span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a>        pe = reward[s,t] - v[choice[s,t]];</span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a>        v[choice[s,t]] = v[choice[s,t]] + lr[s] * pe;</span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a>      }</span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This generates 4000 different simulated datasets. Subsequently, we need to then compare the accuracy of these datasets using <code>R</code>.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Exercise 14">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Exercise 14
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>1. Plot the posterior predictive checks for both models (Simple and Fictitious RL) using the <code>R</code> script <code>comparing_models_ppc.R</code> and examine the output.</strong></p>
</div>
</div>
<p>You should generate the two plots below:</p>
<div style="height: 10px;">

</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../../../images/08.compare_models/ppc.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%"></p>
</figure>
</div>
<div class="image-caption" style="font-size: 1.4em;">
<p>Posterior predictive checks for both models: trial-by-trial choice accuracy (left) and distribution of overall accuracy (right)</p>
</div>
<p>For the time course plot on the left, for each trial, we take all 4000 simulated experiments and <strong>calculate the proportion of correct choices at that trial across all subjects.</strong></p>
<p>For the distribution plot on the right, for each of the 4000 simulated experiments, we <strong>calculate the overall proportion of correct choices across all trials and subjects.</strong> The histograms show the distribution of these 4000 overall proportions, whilst the vertical line shows the actual overall proportion from the real data.</p>
<p>Again, you can see that the straight blue line is closer to the peak for the Fictitious RL compared to the simple RL, demonstrating that this model better captures the true choice behaviour patterns in the data.</p>


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Pitt, M. A., &amp; Myung, I. J. (2002). When a good fit can be bad. Trends in cognitive sciences, 6(10), 421-425.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>Gelman, A., Hwang, J., &amp; Vehtari, A. (2014). Understanding predictive information criteria for Bayesian models. Statistics and computing, 24, 997-1016.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>Vehtari, A., Gabry, J., Magnusson, M., Yao, Y., Bürkner, P., Paananen, T., &amp; Gelman, A. (2024). loo: Efficient leave-one-out cross-validation and WAIC for Bayesian models (Version 2.8.0) [R package]. Retrieved from https://mc-stan.org/loo/<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>Zhang, L., &amp; Gläscher, J. (2020). A brain network supporting social influences in human decision-making. Science advances, 6(34), eabb4159.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>Even though the Stan model code in <code>R</code> uses the same seed, differences in hardware across computers will produce slightly different end results.<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/sohaamir\.github\.io\/BayesCog\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../../workshops/08.compare_models/qmd/intro.html" class="pagination-link" aria-label="Workshop 8: Overview">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Workshop 8: Overview</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../../workshops/09.debugging/qmd/intro.html" class="pagination-link" aria-label="Workshop 9: Overview">
        <span class="nav-page-text">Workshop 9: Overview</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>© Zhang &amp; Sohail, 2025</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/sohaamir/BayesCog/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div></div>
    <div class="nav-footer-right">
<p>This page is built with 🧠, ☕ and <a href="https://quarto.org/">Quarto</a>.</p>
</div>
  </div>
</footer>




</body></html>